{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 0, Iteration 0, Loss: 6.900012969970703\n",
      "Epoch 0, Iteration 10, Loss: 6.378054141998291\n",
      "Epoch 0, Iteration 20, Loss: 6.375323295593262\n",
      "Epoch 0, Iteration 30, Loss: 6.294527530670166\n",
      "Epoch 0, Iteration 40, Loss: 6.292476654052734\n",
      "Epoch 0, Iteration 50, Loss: 6.212110996246338\n",
      "Epoch 0, Iteration 60, Loss: 6.18182373046875\n",
      "Epoch 0, Iteration 70, Loss: 6.207594871520996\n",
      "Epoch 0, Iteration 80, Loss: 6.162230491638184\n",
      "Epoch 0, Iteration 90, Loss: 6.167133331298828\n",
      "Epoch 1, Iteration 0, Loss: 6.218161582946777\n",
      "Epoch 1, Iteration 10, Loss: 6.172418594360352\n",
      "Epoch 1, Iteration 20, Loss: 6.183294296264648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m h_i, h_j, z_i, z_j  \u001b[38;5;241m=\u001b[39m model(images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), images[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     86\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(z_i, z_j, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     89\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ds/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ds/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# train SimCLR on CIFAR-10\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from data import PairTransform, transform\n",
    "from model import SimCLR, nt_xent\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "bsz = 1024\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', transform=PairTransform(transform), download=True)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=bsz, shuffle=True)\n",
    "\n",
    "# Define model, optimizer, and scheduler\n",
    "model = SimCLR(resnet=18, out_dim=128, projection=\"nonlinear\").to(device)\n",
    "criterion = nt_xent\n",
    "optimizer  = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0, last_epoch=-1)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        optimizer.zero_grad() \n",
    "        h_i, h_j, z_i, z_j  = model(images[0].to(device), images[1].to(device))\n",
    "        loss = criterion(z_i, z_j, t=0.5)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Iteration {i}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0, Iteration 0, Loss: 2.504277467727661\n",
      "Epoch 0, Iteration 10, Loss: 2.271807909011841\n",
      "Epoch 0, Iteration 20, Loss: 2.170149803161621\n",
      "Epoch 0, Iteration 30, Loss: 2.124979019165039\n",
      "Epoch 0, Iteration 40, Loss: 2.0536441802978516\n",
      "Epoch 0, Iteration 50, Loss: 2.0429749488830566\n",
      "Epoch 0, Iteration 60, Loss: 2.035769462585449\n",
      "Epoch 1, Iteration 0, Loss: 2.0489633083343506\n",
      "Epoch 1, Iteration 10, Loss: 2.0272107124328613\n",
      "Epoch 1, Iteration 20, Loss: 2.024613380432129\n",
      "Epoch 1, Iteration 30, Loss: 1.9897041320800781\n",
      "Epoch 1, Iteration 40, Loss: 1.9635157585144043\n",
      "Epoch 1, Iteration 50, Loss: 1.8909162282943726\n",
      "Epoch 1, Iteration 60, Loss: 1.8146157264709473\n",
      "Epoch 2, Iteration 0, Loss: 1.7867932319641113\n",
      "Epoch 2, Iteration 10, Loss: 1.7435411214828491\n",
      "Epoch 2, Iteration 20, Loss: 1.6680068969726562\n",
      "Epoch 2, Iteration 30, Loss: 1.6417274475097656\n",
      "Epoch 2, Iteration 40, Loss: 1.6209174394607544\n",
      "Epoch 2, Iteration 50, Loss: 1.6185054779052734\n",
      "Epoch 2, Iteration 60, Loss: 1.629198670387268\n",
      "Epoch 3, Iteration 0, Loss: 1.5955810546875\n",
      "Epoch 3, Iteration 10, Loss: 1.6166496276855469\n",
      "Epoch 3, Iteration 20, Loss: 1.6180261373519897\n",
      "Epoch 3, Iteration 30, Loss: 1.5772093534469604\n",
      "Epoch 3, Iteration 40, Loss: 1.5685229301452637\n",
      "Epoch 3, Iteration 50, Loss: 1.5336147546768188\n",
      "Epoch 3, Iteration 60, Loss: 1.5315452814102173\n",
      "Epoch 4, Iteration 0, Loss: 1.4911454916000366\n",
      "Epoch 4, Iteration 10, Loss: 1.4444254636764526\n",
      "Epoch 4, Iteration 20, Loss: 1.4541393518447876\n",
      "Epoch 4, Iteration 30, Loss: 1.46359384059906\n",
      "Epoch 4, Iteration 40, Loss: 1.4360069036483765\n",
      "Epoch 4, Iteration 50, Loss: 1.4159917831420898\n",
      "Epoch 4, Iteration 60, Loss: 1.3755626678466797\n",
      "Epoch 5, Iteration 0, Loss: 1.3851189613342285\n",
      "Epoch 5, Iteration 10, Loss: 1.4270672798156738\n",
      "Epoch 5, Iteration 20, Loss: 1.4296140670776367\n",
      "Epoch 5, Iteration 30, Loss: 1.3961683511734009\n",
      "Epoch 5, Iteration 40, Loss: 1.4031486511230469\n",
      "Epoch 5, Iteration 50, Loss: 1.4224876165390015\n",
      "Epoch 5, Iteration 60, Loss: 1.3620318174362183\n",
      "Epoch 6, Iteration 0, Loss: 1.336143136024475\n",
      "Epoch 6, Iteration 10, Loss: 1.3683644533157349\n",
      "Epoch 6, Iteration 20, Loss: 1.3165879249572754\n",
      "Epoch 6, Iteration 30, Loss: 1.3108395338058472\n",
      "Epoch 6, Iteration 40, Loss: 1.3205087184906006\n",
      "Epoch 6, Iteration 50, Loss: 1.3544622659683228\n",
      "Epoch 6, Iteration 60, Loss: 1.3048796653747559\n",
      "Epoch 7, Iteration 0, Loss: 1.335026741027832\n",
      "Epoch 7, Iteration 10, Loss: 1.311901569366455\n",
      "Epoch 7, Iteration 20, Loss: 1.2725211381912231\n",
      "Epoch 7, Iteration 30, Loss: 1.3019107580184937\n",
      "Epoch 7, Iteration 40, Loss: 1.3140168190002441\n",
      "Epoch 7, Iteration 50, Loss: 1.2823872566223145\n",
      "Epoch 7, Iteration 60, Loss: 1.2949450016021729\n",
      "Epoch 8, Iteration 0, Loss: 1.219175934791565\n",
      "Epoch 8, Iteration 10, Loss: 1.2686553001403809\n",
      "Epoch 8, Iteration 20, Loss: 1.283868432044983\n",
      "Epoch 8, Iteration 30, Loss: 1.1751585006713867\n",
      "Epoch 8, Iteration 40, Loss: 1.24002206325531\n",
      "Epoch 8, Iteration 50, Loss: 1.250526785850525\n",
      "Epoch 8, Iteration 60, Loss: 1.1703267097473145\n",
      "Epoch 9, Iteration 0, Loss: 1.2926006317138672\n",
      "Epoch 9, Iteration 10, Loss: 1.2186874151229858\n",
      "Epoch 9, Iteration 20, Loss: 1.1906177997589111\n",
      "Epoch 9, Iteration 30, Loss: 1.2026340961456299\n",
      "Epoch 9, Iteration 40, Loss: 1.2523536682128906\n",
      "Epoch 9, Iteration 50, Loss: 1.1937170028686523\n",
      "Epoch 9, Iteration 60, Loss: 1.1932252645492554\n",
      "Accuracy of the network on the 10000 test images: 59.12%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by training a linear classifier on top of the learned features\n",
    "\n",
    "# Define linear classifier\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, feature_extractor, in_dim, out_dim, freeze=True):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        # copy the feature extractor\n",
    "        self.feature_extractor = feature_extractor\n",
    "        # freeze the feature extractor\n",
    "        self.feature_extractor.requires_grad_(not freeze)\n",
    "        self.fc = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.feature_extractor(x))\n",
    "    \n",
    "\n",
    "# Load data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=bsz, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=bsz, shuffle=False)\n",
    "\n",
    "# Define model, optimizer, and scheduler\n",
    "lin_classifier = LinearClassifier(model.resnet, in_dim=512, out_dim=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lin_classifier.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0, last_epoch=-1)\n",
    "\n",
    "# Train\n",
    "for epoch in range(10):\n",
    "    lin_classifier.train()\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lin_classifier(images.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Iteration {i}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "lin_classifier.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = lin_classifier(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), './models/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
